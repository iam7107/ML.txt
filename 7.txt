import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score
df = pd.read_csv('Position_Salaries.csv')
df
df.head()
df.info()
df.describe()
X = df[['Level']].values # Features (Level)
y = df['Salary'].values # Target (Salary)
lin_reg = LinearRegression()
lin_reg.fit(X, y)
y_pred_linear = lin_reg.predict(X)
r2_linear = r2_score(y, y_pred_linear)

print(f"R2 Score of Simple Linear Regression: {r2_linear}")
plt.scatter(X, y, color='red', label='Actual data')
plt.plot(X, y_pred_linear, color='blue', label='Linear Regression')
plt.title('Salary vs. Level')
plt.xlabel('Level')
plt.ylabel('Salary')
plt.legend()
plt.show()
levels_to_predict = np.array([[11], [12]])

salary_pred_linear = lin_reg.predict(levels_to_predict)
print(f"Linear Regression Predictions for Levels 11 and 12:{salary_pred_linear}")






#q2
# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import CategoricalNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Create a sample weather forecast dataset
data = {
    'Outlook': ['Sunny', 'Overcast', 'Rain', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Rain', 'Sunny', 'Rain'],
    'Temperature': ['Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Hot', 'Mild', 'Cool', 'Mild', 'Mild'],
    'Humidity': ['High', 'High', 'High', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'High', 'Normal'],
    'Windy': [False, False, False, True, False, True, True, False, True, True],
    'Play': ['No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No']
}
df = pd.DataFrame(data)

# Step 1: Convert categorical features into numeric format using one-hot encoding
df_encoded = pd.get_dummies(df, columns=['Outlook', 'Temperature', 'Humidity', 'Windy'])

# Step 2: Split the dataset into features and target
X = df_encoded.drop(columns=['Play'])
y = df['Play']

# Step 3: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train the Naive Bayes model
model = CategoricalNB()
model.fit(X_train, y_train)

# Step 5: Make predictions on the test set
y_pred = model.predict(X_test)

# Step 6: Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Model Performance:")
print(f"Accuracy: {accuracy * 100:.2f}%")

# Detailed classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred, labels=['Yes', 'No'])
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Yes', 'No'], yticklabels=['Yes', 'No'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for Naive Bayes Classifier")
plt.show()
