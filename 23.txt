#Q1
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score

df = pd.read_csv('Position_Salaries.csv')
df

df.head()

df.info()

df.describe()

X = df[['Level']].values # Features (Level)
y = df['Salary'].values # Target (Salary)

lin_reg = LinearRegression()
lin_reg.fit(X, y)

y_pred_linear = lin_reg.predict(X)
r2_linear = r2_score(y, y_pred_linear)
print(f"R2 Score of Simple Linear Regression: {r2_linear}")

plt.scatter(X, y, color='red', label='Actual data')
plt.plot(X, y_pred_linear, color='blue', label='Linear Regression')
plt.title('Salary vs. Level')
plt.xlabel('Level')
plt.ylabel('Salary')
plt.legend()
plt.show()

levels_to_predict = np.array([[11], [12]])
salary_pred_linear = lin_reg.predict(levels_to_predict)
print(f"Linear Regression Predictions for Levels 11 and 12:{salary_pred_linear}")









#Q2
import pandas as pd

df = pd.read_csv('housing_prices.csv')
df

# Step 2: Check for missing (null) values in the dataset
print("Missing values in each column:")
print(df.isnull().sum())

# Step 3: Remove rows with any missing values
df_cleaned = df.dropna()

# Step 4: Alternatively, you can remove columns with missing values (if necessary)
# df_cleaned = df.dropna(axis=1)

# Step 5: Verify the removal of missing values
print("\nDataset after removing rows with missing values:")
print(df_cleaned)
